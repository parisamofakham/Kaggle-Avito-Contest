{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Environment Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from scipy.stats import itemfreq\n",
    "from scipy import ndimage as ndi\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import feature\n",
    "from PIL import Image as IMG\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import operator\n",
    "import cv2\n",
    "import os \n",
    "from multiprocessing import Pool\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define features to extract from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# arbitrarily define light and dark level for pixels and get the dark and light level for the image\n",
    "# the idea is from kernel:\n",
    "# https://www.kaggle.com/shivamb/ideas-for-image-features-and-image-quality\n",
    "\n",
    "def color_analysis(img):\n",
    "    # obtain the color palatte of the image \n",
    "    palatte = defaultdict(int)\n",
    "    for pixel in img.getdata():\n",
    "        palatte[pixel] += 1\n",
    "    \n",
    "    # sort the colors present in the image \n",
    "    sorted_x = sorted(palatte.items(), key=operator.itemgetter(1), reverse = True)\n",
    "    light_shade, dark_shade, shade_count, pixel_limit = 0, 0, 0, 25\n",
    "    for i, x in enumerate(sorted_x[:pixel_limit]):\n",
    "        # dull : too much darkness \n",
    "        if all(xx <= 20 for xx in x[0][:3]):\n",
    "            dark_shade += x[1]\n",
    "        # bright : too much whiteness \n",
    "        if all(xx >= 240 for xx in x[0][:3]): \n",
    "            light_shade += x[1]\n",
    "        shade_count += x[1]\n",
    "        \n",
    "    light_percent = round((float(light_shade)/shade_count)*100, 2)\n",
    "    dark_percent = round((float(dark_shade)/shade_count)*100, 2)\n",
    "    return light_percent, dark_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utilize the color analysis function and get light score from image\n",
    "def perform_white_analysis(img):\n",
    "    try:\n",
    "        if pd.notnull(img):\n",
    "            flag=\"white\"\n",
    "            path = images_path + img +\".jpg\"\n",
    "            im = IMG.open(path) #.convert(\"RGB\")\n",
    "\n",
    "            # cut the images into two halves as complete average may give bias results\n",
    "            size = im.size\n",
    "            halves = (size[0]/2, size[1]/2)\n",
    "            im1 = im.crop((0, 0, size[0], halves[1]))\n",
    "            im2 = im.crop((0, halves[1], size[0], size[1]))\n",
    "\n",
    "            try:\n",
    "                light_percent1, dark_percent1 = color_analysis(im1)\n",
    "                light_percent2, dark_percent2 = color_analysis(im2)\n",
    "            except Exception as e:\n",
    "                return None\n",
    "\n",
    "            light_percent = (light_percent1 + light_percent2)/2 \n",
    "            dark_percent = (dark_percent1 + dark_percent2)/2 \n",
    "\n",
    "            if flag == 'black':\n",
    "                return dark_percent\n",
    "            elif flag == 'white':\n",
    "                return light_percent\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            return -999\n",
    "    except:\n",
    "        return -999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utilize the color analysis function and get light score from image\n",
    "def perform_black_analysis(img):\n",
    "    try:\n",
    "        if pd.notnull(img):\n",
    "            flag=\"black\"\n",
    "            path = images_path + img +\".jpg\"\n",
    "            im = IMG.open(path) #.convert(\"RGB\")\n",
    "\n",
    "            # cut the images into two halves as complete average may give bias results\n",
    "            size = im.size\n",
    "            halves = (size[0]/2, size[1]/2)\n",
    "            im1 = im.crop((0, 0, size[0], halves[1]))\n",
    "            im2 = im.crop((0, halves[1], size[0], size[1]))\n",
    "\n",
    "            try:\n",
    "                light_percent1, dark_percent1 = color_analysis(im1)\n",
    "                light_percent2, dark_percent2 = color_analysis(im2)\n",
    "            except Exception as e:\n",
    "                return None\n",
    "\n",
    "            light_percent = (light_percent1 + light_percent2)/2 \n",
    "            dark_percent = (dark_percent1 + dark_percent2)/2 \n",
    "\n",
    "            if flag == 'black':\n",
    "                return dark_percent\n",
    "            elif flag == 'white':\n",
    "                return light_percent\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            return -999\n",
    "    except:\n",
    "        return -999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get image size\n",
    "# we thought that length and width are the same feature for image, so we sum them up as size feature\n",
    "def image_size(img):\n",
    "    try:\n",
    "        if pd.notnull(img):\n",
    "            path = images_path + img +\".jpg\"\n",
    "            im = IMG.open(path)    \n",
    "            wandl=im.size[0]+im.size[1]\n",
    "            return wandl\n",
    "        else:\n",
    "            return -999\n",
    "    except:\n",
    "        return -999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some images may contain no pixel variation and are entirely uniform.\n",
    "# Average Pixel Width is a measure which indicates the amount of edges present in the image.\n",
    "# If this number comes out to be very low, then the image is most likely a uniform image and may not represent right content.\n",
    "def average_pixel_width(img):\n",
    "    try:\n",
    "        if pd.notnull(img):\n",
    "            path = images_path + img +\".jpg\"\n",
    "            im = IMG.open(path)    \n",
    "            im_array = np.asarray(im.convert(mode='L'))\n",
    "            edges_sigma1 = feature.canny(im_array, sigma=3)\n",
    "            apw = (float(np.sum(edges_sigma1)) / (im.size[0]*im.size[1]))\n",
    "            return apw*100\n",
    "        else:\n",
    "            return -999\n",
    "    except:\n",
    "        return -999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# colors might influence the deal probability, so we calculated average colors to show the image overall color conditions\n",
    "def get_average_color(img):\n",
    "    try:\n",
    "        if pd.notnull(img):\n",
    "            path = images_path + img +\".jpg\"\n",
    "            img = cv2.imread(path)\n",
    "            average_color = [img[:, :, i].mean() for i in range(img.shape[-1])]\n",
    "            return average_color\n",
    "        else:\n",
    "            return [-999,-999,-999]\n",
    "    except:\n",
    "        return -999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reference:\n",
    "# https://www.pyimagesearch.com/2015/09/07/blur-detection-with-opencv/\n",
    "def get_blurrness_score(img):\n",
    "    try:\n",
    "        if pd.notnull(img):\n",
    "            path = images_path + img +\".jpg\"\n",
    "            image = cv2.imread(path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            fm = cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "            return fm\n",
    "        else:\n",
    "            return -999\n",
    "    except:\n",
    "        return -999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check all the functions we defined to extract image features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Functions Defined\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'average_pixel_width': <function __main__.average_pixel_width>,\n",
       " 'color_analysis': <function __main__.color_analysis>,\n",
       " 'get_average_color': <function __main__.get_average_color>,\n",
       " 'get_blurrness_score': <function __main__.get_blurrness_score>,\n",
       " 'image_size': <function __main__.image_size>,\n",
       " 'perform_black_analysis': <function __main__.perform_black_analysis>,\n",
       " 'perform_white_analysis': <function __main__.perform_white_analysis>}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import inspect\n",
    "from os.path import join\n",
    "\n",
    "print (\"Current Functions Defined\")\n",
    "dict(inspect.getmembers(sys.modules[__name__],predicate = lambda f: inspect.isfunction(f) and f.__module__ == __name__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mydf=pd.read_csv(\"~/.kaggle/competitions/avito-demand-prediction/test.csv\",header=0)\n",
    "images_path=\"/home/ubuntu/.kaggle/competitions/avito-demand-prediction/data/competition_files/test_jpg/\"\n",
    "mydf.to_csv(\"mydf.csv\",encoding=\"utf-8\",header=True,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We need to analyze about 2 million images and most analysis is pixel-wise analysis.\n",
    "#### So, we used a 32-core instance in AWS to handle the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We use multiprocessing to separate data into 32 parts and analyze them simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "\n",
    "time1=time.time()\n",
    "\n",
    "# Number of CPU cores on your system\n",
    "cores = 32\n",
    "# Define as many partitions as you want\n",
    "partitions = cores\n",
    "\n",
    "funclist=[perform_white_analysis,perform_black_analysis,image_size,average_pixel_width,get_average_color,get_blurrness_score]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In each iteration, we extract one feature and output the file into csv.\n",
    "### The overall run time for training data is around 20 hours (test data: 5 hours) in the 32-core machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading files\n",
      "parallelizing dataframe\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "perform_black_analysis  completed\n",
      "running for  40  mins\n",
      "reading files\n",
      "parallelizing dataframe\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "image_size  completed\n",
      "running for  41  mins\n",
      "reading files\n",
      "parallelizing dataframe\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "average_pixel_width  completed\n",
      "running for  70  mins\n",
      "reading files\n",
      "parallelizing dataframe\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "get_average_color  completed\n",
      "running for  71  mins\n",
      "reading files\n",
      "parallelizing dataframe\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "applying function\n",
      "get_blurrness_score  completed\n",
      "running for  81  mins\n"
     ]
    }
   ],
   "source": [
    "for myfunc in funclist:\n",
    "    print (\"reading files\")\n",
    "    mydf=pd.read_csv(\"mydf.csv\",header=0,encoding=\"utf-8\")\n",
    "    images_path=\"/home/ubuntu/.kaggle/competitions/avito-demand-prediction/data/competition_files/test_jpg/\"\n",
    "    def parallelize_dataframe(data, func):\n",
    "        print (\"parallelizing dataframe\")\n",
    "        data_split = np.array_split(data, partitions)\n",
    "        pool = Pool(cores)\n",
    "        data = pd.concat(pool.map(func, data_split))\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        return data\n",
    "\n",
    "    def test_func(data):\n",
    "        print (\"applying function\")\n",
    "        data[str(myfunc.__name__)] = data[\"image\"].apply(myfunc)\n",
    "        return data\n",
    "    \n",
    "    mydf = parallelize_dataframe(mydf, test_func)\n",
    "    mydf.to_csv(\"mydf.csv\",header=True,index=False,encoding=\"utf-8\")\n",
    "    print (myfunc.__name__,\" completed\")\n",
    "    print (\"running for \",round((time.time()-time1)/60),\" mins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### get_average_color output the color in 0-255 color range. We can transform it to 0-1 range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "mydf=pd.read_csv(\"mydf.csv\",header=0,encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mydf[\"get_average_color\"]=mydf[\"get_average_color\"].apply(lambda x: x.strip(\"[\").strip(\"]\").replace(\" \",\"\").split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# always replace NA or other errors with -999\n",
    "def mycolor(x,y):\n",
    "    try:\n",
    "        if float(x[y])==-999:\n",
    "            return -999\n",
    "        else:\n",
    "            return round(float(x[y])/255,2)\n",
    "    except:\n",
    "        return -999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mydf['average_red'] = mydf['get_average_color'].apply(lambda x: mycolor(x,0))\n",
    "mydf['average_green'] = mydf['get_average_color'].apply(lambda x: mycolor(x,1))\n",
    "mydf['average_blue'] = mydf['get_average_color'].apply(lambda x: mycolor(x,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mydf.drop(['get_average_color'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>region</th>\n",
       "      <th>city</th>\n",
       "      <th>parent_category_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>param_1</th>\n",
       "      <th>param_2</th>\n",
       "      <th>param_3</th>\n",
       "      <th>title</th>\n",
       "      <th>...</th>\n",
       "      <th>image</th>\n",
       "      <th>image_top_1</th>\n",
       "      <th>perform_white_analysis</th>\n",
       "      <th>perform_black_analysis</th>\n",
       "      <th>image_size</th>\n",
       "      <th>average_pixel_width</th>\n",
       "      <th>get_blurrness_score</th>\n",
       "      <th>average_red</th>\n",
       "      <th>average_green</th>\n",
       "      <th>average_blue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6544e41a8817</td>\n",
       "      <td>dbe73ad6e4b5</td>\n",
       "      <td>Волгоградская область</td>\n",
       "      <td>Волгоград</td>\n",
       "      <td>Личные вещи</td>\n",
       "      <td>Детская одежда и обувь</td>\n",
       "      <td>Для мальчиков</td>\n",
       "      <td>Обувь</td>\n",
       "      <td>25</td>\n",
       "      <td>Отдам бесплатно</td>\n",
       "      <td>...</td>\n",
       "      <td>a8b57acb5ab304f9c331ac7a074219aed4d349d8aef386...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>23.380</td>\n",
       "      <td>25.640</td>\n",
       "      <td>840</td>\n",
       "      <td>3.831019</td>\n",
       "      <td>313.475352</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65b9484d670f</td>\n",
       "      <td>2e11806abe57</td>\n",
       "      <td>Свердловская область</td>\n",
       "      <td>Нижняя Тура</td>\n",
       "      <td>Хобби и отдых</td>\n",
       "      <td>Велосипеды</td>\n",
       "      <td>Дорожные</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Продам велосипед</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8bab230b2ecd</td>\n",
       "      <td>0b850bbebb10</td>\n",
       "      <td>Новосибирская область</td>\n",
       "      <td>Бердск</td>\n",
       "      <td>Бытовая электроника</td>\n",
       "      <td>Аудио и видео</td>\n",
       "      <td>Телевизоры и проекторы</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BBK</td>\n",
       "      <td>...</td>\n",
       "      <td>8c361112cb049745ef2d1b0ae73594fc5c107286b0c942...</td>\n",
       "      <td>2960.0</td>\n",
       "      <td>6.285</td>\n",
       "      <td>93.715</td>\n",
       "      <td>1000</td>\n",
       "      <td>4.937934</td>\n",
       "      <td>754.228030</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8e348601fefc</td>\n",
       "      <td>5f1d5c3ce0da</td>\n",
       "      <td>Саратовская область</td>\n",
       "      <td>Саратов</td>\n",
       "      <td>Для дома и дачи</td>\n",
       "      <td>Бытовая техника</td>\n",
       "      <td>Для кухни</td>\n",
       "      <td>Вытяжки</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Вытяжка Jetair 60</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8bd2fe400b89</td>\n",
       "      <td>23e2d97bfc7f</td>\n",
       "      <td>Оренбургская область</td>\n",
       "      <td>Бузулук</td>\n",
       "      <td>Личные вещи</td>\n",
       "      <td>Товары для детей и игрушки</td>\n",
       "      <td>Детские коляски</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Коляска зима-лето</td>\n",
       "      <td>...</td>\n",
       "      <td>bc3cf6deef10840fc302e38eb48fa7748aa1e28d534f8f...</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>53.820</td>\n",
       "      <td>840</td>\n",
       "      <td>3.735532</td>\n",
       "      <td>344.755778</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id       user_id                 region         city  \\\n",
       "0  6544e41a8817  dbe73ad6e4b5  Волгоградская область    Волгоград   \n",
       "1  65b9484d670f  2e11806abe57   Свердловская область  Нижняя Тура   \n",
       "2  8bab230b2ecd  0b850bbebb10  Новосибирская область       Бердск   \n",
       "3  8e348601fefc  5f1d5c3ce0da    Саратовская область      Саратов   \n",
       "4  8bd2fe400b89  23e2d97bfc7f   Оренбургская область      Бузулук   \n",
       "\n",
       "  parent_category_name               category_name                 param_1  \\\n",
       "0          Личные вещи      Детская одежда и обувь           Для мальчиков   \n",
       "1        Хобби и отдых                  Велосипеды                Дорожные   \n",
       "2  Бытовая электроника               Аудио и видео  Телевизоры и проекторы   \n",
       "3      Для дома и дачи             Бытовая техника               Для кухни   \n",
       "4          Личные вещи  Товары для детей и игрушки         Детские коляски   \n",
       "\n",
       "   param_2 param_3              title      ...       \\\n",
       "0    Обувь      25    Отдам бесплатно      ...        \n",
       "1      NaN     NaN   Продам велосипед      ...        \n",
       "2      NaN     NaN                BBK      ...        \n",
       "3  Вытяжки     NaN  Вытяжка Jetair 60      ...        \n",
       "4      NaN     NaN  Коляска зима-лето      ...        \n",
       "\n",
       "                                               image  image_top_1  \\\n",
       "0  a8b57acb5ab304f9c331ac7a074219aed4d349d8aef386...       2020.0   \n",
       "1                                                NaN          NaN   \n",
       "2  8c361112cb049745ef2d1b0ae73594fc5c107286b0c942...       2960.0   \n",
       "3                                                NaN          NaN   \n",
       "4  bc3cf6deef10840fc302e38eb48fa7748aa1e28d534f8f...       1002.0   \n",
       "\n",
       "   perform_white_analysis perform_black_analysis image_size  \\\n",
       "0                  23.380                 25.640        840   \n",
       "1                -999.000               -999.000       -999   \n",
       "2                   6.285                 93.715       1000   \n",
       "3                -999.000               -999.000       -999   \n",
       "4                   0.000                 53.820        840   \n",
       "\n",
       "  average_pixel_width  get_blurrness_score  average_red  average_green  \\\n",
       "0            3.831019           313.475352         0.41           0.42   \n",
       "1         -999.000000          -999.000000      -999.00        -999.00   \n",
       "2            4.937934           754.228030         0.34           0.30   \n",
       "3         -999.000000          -999.000000      -999.00        -999.00   \n",
       "4            3.735532           344.755778         0.23           0.27   \n",
       "\n",
       "   average_blue  \n",
       "0          0.42  \n",
       "1       -999.00  \n",
       "2          0.28  \n",
       "3       -999.00  \n",
       "4          0.36  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n"
     ]
    }
   ],
   "source": [
    "mydf.to_csv(\"testwithimagefeatures.csv\",header=True,index=False,encoding=\"utf-8\")\n",
    "print (\"completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# silimarly we can change the path and file name to analyze both training and test data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
